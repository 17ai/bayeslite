{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satellites Tutorial\n",
    "\n",
    "In this example we will explore the core functionality of BayesDB by using BayesDB to explore and analyze some real data. The data we will use is the Union of Concerned Scientists' Satellites data. The data is a catalogue of satellites. Each row of the data represents a satellite and each column is a feature of that satellite such as dry mass, orbit type, launch date, perigee, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a table\n",
    "\n",
    "We first open our Bayesian database that contains the Bayesian model of the satellites data. This database resides on disk in the form of a `.bdb` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bayeslite\n",
    "import sys\n",
    "import bayeslite.shell.pretty as pretty\n",
    "satellites_bdb = bayeslite.bayesdb_open(pathname='satellites.bdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This database contains a BayesDB table named `satellites`. We this table with the original raw data, which are in csv format with a header containing the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayeslite.bayesdb_read_csv_file(satellites_bdb, \"satellites\", \"satellites.csv\", \n",
    "                                header=True, create=True, ifnotexists=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we have the table, we can list the columns with their statistical types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bdbcontrib\n",
    "bdbcontrib.bql_utils.get_column_info(satellites_bdb, 'satellites_cc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select data just as we would in SQL in BQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bdbcontrib.facade import do_query\n",
    "do_query(satellites_bdb,\n",
    "        'SELECT name, dry_mass_kg, period_minutes, class_of_orbit FROM satellites LIMIT 10;').as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use visualization tools such as `histogram` to plot emperical frequencies. In the next example, the first argument `dry_mass_kg` is a `NUMERICAL` variable, and is plotted in different colors based on the `class_of_orbit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "_ = bdbcontrib.histogram(satellites_bdb, 'SELECT dry_mass_kg, class_of_orbit FROM satellites', bins=35, normed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to tell BayesDB which values to treat as missing, NULL. Different datasets use different markers for missing data, this dataset uses NaN. To convert all instances of NaN to SQL NULL, we use the .nullify command, followed by the table, followed by the value to convert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bdbcontrib.nullify(satellites_bdb, 'satellites', 'NaN')\n",
    "do_query(satellites_bdb, 'SELECT name, dry_mass_kg FROM satellites LIMIT 10').as_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "do_query(satellites_bdb, 'SELECT COUNT(*) FROM satellites;').as_df()\n",
    "do_query(satellites_bdb, 'SELECT COUNT(*) FROM satellites WHERE type_of_orbit IS NULL;').as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Models of the Data\n",
    "\n",
    "Before you can use BQL modelling for your data, you must use register a metamodel, such as the Crosscat metamodel with which the `.bdb` file was built.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import crosscat.LocalEngine\n",
    "import bayeslite.crosscat\n",
    "crosscat_engine = crosscat.LocalEngine.LocalEngine(seed=0)\n",
    "crosscat_metamodel = bayeslite.crosscat.CrosscatMetamodel(crosscat_engine)\n",
    "bayeslite.bayesdb_register_metamodel(satellites_bdb, crosscat_metamodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now begin to ask BayesDB questions about the implications of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring Values\n",
    "\n",
    "Inferring is like imputing. `INFER` produces a summary value for a missing (`NULL`) entry. If we use the `EXPLICIT` keyword, we can re-infer present values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will impute missing values of type_of_orbit. Let us see how many values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "do_query(satellites_bdb, 'SELECT COUNT(*) FROM satellites WHERE type_of_orbit IS NULL;').as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the INFER EXPLICIT query to impute all missing values, and let BayesDB tell us the belief of its reported value. First we will pull out anticipated_lifetime, perigee_km, period_minutes, and class_of_orbit exactly as they appear in the table. Next we will use the special BQL expression PREDICT <col_name> CONFIDENCE <conf_name>, which will retrun two values: first, a prediction for <col_name> and second a confidence level for the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "do_query(satellites_bdb, '''\n",
    "CREATE TEMP TABLE inferred_orbit AS\n",
    "INFER EXPLICIT\n",
    "anticipated_lifetime, perigee_km, period_minutes, class_of_orbit,\n",
    "PREDICT type_of_orbit AS inferred_orbit_type\n",
    "CONFIDENCE inferred_orbit_type_conf\n",
    "FROM satellites_cc\n",
    "WHERE type_of_orbit IS NULL;\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the result both in tabular and graphical form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "do_query(satellites_bdb, 'SELECT * FROM inferred_orbit;').as_df()\n",
    "bdbcontrib.pairplot(satellites_bdb,'''\n",
    "    SELECT inferred_orbit_type, inferred_orbit_type_conf, class_of_orbit FROM inferred_orbit;\n",
    "''', colorby='class_of_orbit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we shall impute missing values of dry_mass_kg. First, let us see how many values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "do_query(satellites_bdb, 'SELECT COUNT(*) FROM satellites WHERE dry_mass_kg IS NULL;').as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly half the values of dry mass are missing! We can visualize missing values in pairs of continuous columns using the `pairplot` visualization command with the `show-missing` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = bdbcontrib.pairplot(satellites_bdb, 'SELECT dry_mass_kg, launch_mass_kg FROM satellites WHERE class_of_orbit = GEO;', show_missing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values are represented as lines along their missing dimension. This way, we can see which values of the missing dimensions are more likely by observing where the lines intersect with the existing data points.\n",
    "\n",
    "We will use the INFER command to impute missing values for geosynchronous satellites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bdbcontrib.pairplot(satellites_bdb, '''\n",
    "INFER dry_mass_kg AS \"Inferred Dry Mass (confidence 0)\", \n",
    "    launch_mass_kg AS \"Inferred Launch Mass (confidence 0)\"\n",
    "    WITH CONFIDENCE 0\n",
    "    FROM satellites_cc\n",
    "    WHERE class_of_orbit = GEO;\n",
    "''', show_missing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No more missing values. Notice the WITH CONFIDENCE clause. This tells BayesDB to impute entries only if it is confident to a certain degree. WITH CONFIDENCE 0 will then impute all values regardless; if we asked for confidence of 0.6 fewer entries (or perhaps none at all) would be filled in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdbcontrib.pairplot(satellites_bdb, '''\n",
    "INFER dry_mass_kg AS \"Inferred Dry Mass (confidence 0.6)\",\n",
    "    launch_mass_kg AS \"Inferred Launch Mass (confidence 0.6)\"\n",
    "    WITH CONFIDENCE 0.6 \n",
    "    FROM satellites_cc\n",
    "    WHERE class_of_orbit = GEO;'\n",
    "''', show_missing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the number of red lines is exactly the same as before. This is because BayesDB does not have enough confidence (0.6) to fill in any missing values for dry_mass_kg.\n",
    "\n",
    "BayesDB's notion of CONFIDENCE is unlike confidence in standard statistics. Whereas in standard statistics 'confidence' is typically paired with the word 'interval' to describe some region of probability mass, CONFIDENCE in BayesDB is a measure of inter-model agreement; that is, CONFIDENCE is the probability that among the models, there is a unimodal summary of the value we wish to impute given all other entries in that entry's row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characterizing dependence between variables\n",
    "\n",
    "\n",
    "Now that the analyses are finished, we can begin to ask BayesDB questions about the implications of the data. Often the first question we want to ask, especially if we are relatively clueless about the data, is which columns are most likely dependent on each other.\n",
    "\n",
    "One of the most common statistical techniques for detecting dependence between variables is using correlation coefficients. BayesDB has the ability to compute observed correlation coefficients and their associated pvalues between all the pairs of columns, using the ESTIMATE PAIRWISE command; and because we do not want to look at at a very long table, we will visualize it in a heatmap using the `heatmap` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustermap = bdbcontrib.heatmap(satellites_bdb,\n",
    "    'ESTIMATE CORRELATION FROM PAIRWISE COLUMNS OF satellites_cc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BayesDB has a more powerful notion of dependence called DEPENDENCE PROBABILITY, which is the degree of belief that two columns have some dependence. First let us see the probability that each column depdnds on perigee_km, and longitude_radians_of_geo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "do_query(satellites_bdb, '''ESTIMATE COLUMNS DEPENDENCE PROBABILITY WITH perigee_km AS\n",
    "\"Probability of Dependence with Perigee\"\n",
    "FROM satellites_cc\n",
    "ORDER BY \"Probability of Dependence with Perigee\" DESC LIMIT 10;\n",
    "''').as_df()\n",
    "do_query(satellites_bdb, '''\n",
    "ESTIMATE COLUMNS DEPENDENCE PROBABILITY WITH longitude_radians_of_geo AS\n",
    "\"Probability of Dependence with Longitude Radians\"\n",
    "FROM satellites_cc\n",
    "ORDER BY \"Probability of Dependence with Longitude Radians\" DESC LIMIT 10;\n",
    "''').as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now view all pairwise dependencies probabilities using the `heatmap` command. The entries along the diagnoal are 1, since each variable is dependent with itself. Notice that DEPENDENCE PROBABILITY determines a richer network of relationships than standard measures of correlation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bdbcontrib.facade import do_query\n",
    "        'SELECT name, dry_mass_kg, period_minutes, class_of_orbit FROM satellites;').as_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdbcontrib.heatmap(satellites_bdb, 'ESTIMATE PAIRWISE DEPENDENCE PROBABILITY FROM satellites_cc;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each cell in the heatmap represents the dependence probability between a pair of columns. Darker cells represent higher dependence probability. The dendrogram is primarily for visualization, but clusters columns roughly into dependent groups. Note which groups of columns have the highest dependence probability. Do you notice any patterns? Many of the variables in this table are nearly deterministic, given the laws of physics. For example, we can determine a satellite's orbital period (the amount of time an orbit takes) form its perigee (lowest altitude of the orbit) and apogee (highest altitude of the orbit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which variables predict anticipated_lifetime --- which are the main predictors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "do_query(satellites_bdb, '''\n",
    "ESTIMATE COLUMNS DEPENDENCE PROBABILITY WITH anticipated_lifetime AS \n",
    "    \"Probability of Dependence with Lifetime\"\n",
    "    FROM satellites_cc\n",
    "    ORDER BY \"Probability of Dependence with Lifetime\" DESC LIMIT 10;\n",
    "''').as_df()\n",
    "\n",
    "bdbcontrib.pairplot(satellites_bdb, '''\n",
    "SELECT anticipated_lifetime, period_minutes, launch_mass_kg, dry_mass_kg, inclination_radians FROM satellites;\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the dependencies for other variables such as `purpose`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "do_query(satellites_bdb, '''\n",
    "ESTIMATE COLUMNS DEPENDENCE PROBABILITY WITH purpose AS\n",
    "    \"Probability of Dependence with Purpose\"\n",
    "    FROM satellites_cc\n",
    "    ORDER BY \"Probability of Dependence with Purpose\" DESC LIMIT 10;\n",
    "''').as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify satellites with unlikely lifetimes\n",
    "\n",
    "We can use BayesDB to identify anomalous values in our table. An anomaly\n",
    "is different from an outlier. An anomalous value is an observed value that\n",
    "has a low probability under the inferred model; and outlier is defined\n",
    "simply as having an extreme value. We can visualize this idea by creating\n",
    "a scatter plot of data and their predictive probability functions\n",
    "(`PREDICTIVE PROBABILITY`). We use the `ESTIMATE` keyword rather than\n",
    "`SELECT` because we are asking questions of the generator. We also\n",
    "specify that we only want the probabilities of non-null values using a\n",
    "`WHERE` clause (the predictive probability of `NULL` is `NULL`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdbcontrib.pairplot(satellites_bdb, '''ESTIMATE anticipated_lifetime,\n",
    "PREDICTIVE PROBABILITY OF anticipated_lifetime AS \"Relative Probability of Lifetime\",\n",
    "class_of_orbit\n",
    "FROM satellites_cc\n",
    "WHERE anticipated_lifetime IS NOT NULL;\n",
    "''', colorby='class_of_orbit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are plenty of non-extreme values that have low probabilities.\n",
    "Let us get a list of the 10 most anomalous satellites by sorting by\n",
    "`relative probability of lifetime` in ascending (`ASC`) order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "do_query(satellites_bdb, '''\n",
    "CREATE TEMP TABLE unlikely_lifetimes AS ESTIMATE name, anticipated_lifetime,\n",
    "PREDICTIVE PROBABILITY OF anticipated_lifetime \n",
    "AS \"Relative Probability of Lifetime\"\n",
    "FROM satellites_cc;\n",
    "''').as_df()\n",
    "\n",
    "do_query(satellites_bdb, '''\n",
    "SELECT * FROM unlikely_lifetimes\n",
    "WHERE Anticipated_Lifetime IS NOT NULL \n",
    "ORDER BY \"Relative Probability of Lifetime\" ASC LIMIT 10;\n",
    "''').as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other values in the table with unlikely anticipated lifetimes, although\n",
    "it is not entirely clear why BayesDB has identified them as such. To determine\n",
    "why `Sicral 1A`, for instance, has a low probability lifetime, let us query\n",
    "the satellites which BayesDB believes are similar to `Sicral 1A` using the\n",
    "`SIMILARITY TO` query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "do_query(satellites_bdb, '''\n",
    "CREATE TEMP TABLE similiarity_to_sicral1a AS\n",
    "ESTIMATE name, anticipated_lifetime,\n",
    "SIMILARITY TO (name = 'Sicral 1A') AS sim_to_sicral\n",
    "FROM satellites_cc;\n",
    "''').as_df()\n",
    "    \n",
    "do_query(satellites_bdb, '''\n",
    "SELECT * FROM similiarity_to_sicral1a \n",
    "ORDER BY sim_to_sicral DESC LIMIT 10;\n",
    "''').as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the satellites that BayesDB believes are similar to `Sicral 1A` have lifetimes\n",
    "between 5 to 12 years, except for its sister satellite `Sicral 1B` which is\n",
    "also an anomaly. Furthe research on these two satellites indicates that their\n",
    "actual anticipated lifetime is 10 years; the database entry is an error.\n",
    "\n",
    "\n",
    "Recall earlier that we mentioned that some of the relations are governed by\n",
    "the laws of physics and are thus nearly deterministic? We can use this\n",
    "determinism coupled with our notion of anomalousness to search the table for\n",
    "data-entry errors. A geosynchronous orbit should take 24 hours\n",
    "(1440 minutes). Let us display the anomalous values for satellites in\n",
    "geosynchronous orbit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "do_query(satellites_bdb, '''\n",
    "CREATE TEMP TABLE unlikely_periods AS ESTIMATE name, class_of_orbit, period_minutes,\n",
    "PREDICTIVE PROBABILITY OF period_minutes AS \"Relative Probability of Period\"\n",
    "FROM satellites_cc;\n",
    "''').as_df()\n",
    "    \n",
    "do_query(satellites_bdb, '''\n",
    "SELECT * FROM unlikely_periods\n",
    "WHERE class_of_orbit IS GEO AND period_minutes IS NOT NULL\n",
    "ORDER BY \"Relative Probability of Period\" ASC LIMIT 10;\n",
    "''').as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a couple of oddities. There are satellites with 24-minute periods. It\n",
    "appears that these entries are in hours rather than minutes. There are other\n",
    "entries that have too-short periods, which appear to be decimal errors.\n",
    "\n",
    "\n",
    "**NOTE:** We have reported these errors to the database maintainers.\n",
    "\n",
    "\n",
    "## Simulating entries\n",
    "\n",
    "Suppose that we saw a satellite in geosynchrous orbit with a mass of\n",
    "500kg; who launched it, and what is its purpose? We can ask BayesDB to simulate\n",
    "this scenario for us. We will do this in two queries. In the first query, we\n",
    "will create a temporary table (`TEMP TABLE`) consisting of simulated data using\n",
    "the `SIMULATE` keyword (see Notes for more info about temporary tables); in the\n",
    "second query, we will concatenate and organize the data for easy reading.\n",
    "\n",
    "We `SIMULATE` the `Country` and `Purpose` variables, `GIVEN` that we have\n",
    "observed the `Class_of_Orbit` and `Dry_Mass` (1000 simulations).\n",
    "We specify the number of points to simulate using `LIMIT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "do_query(satellites_bdb, '''\n",
    "CREATE TEMP TABLE satellite_purpose AS\n",
    "SIMULATE country_of_operator, purpose FROM satellites_cc\n",
    "GIVEN Class_of_orbit = GEO, Dry_mass_kg = 500 \n",
    "LIMIT 1000;\n",
    "''').as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that everything after the `AS` is a perfectly valid query. `CREATE\n",
    "TEMP TABLE satellite_purpose AS` saves the result of the query that follows it\n",
    "into a table called `satellite_purpose` which we can refer to later. Temporary\n",
    "tables are destroyed when the session is closed.\n",
    "\n",
    "To determine which country-purpose combination is most probable\n",
    "we will concatenate the values of the first two columns into a single\n",
    "country-purpose column using the `||` operator, and then use SQLite's\n",
    "`COUNT` function to calculate the frequencies. Let us look at the top 10\n",
    "most frequent user-purpose combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "do_query(satellites_bdb, '''\n",
    "SELECT country_of_operator || \"--\" || purpose AS \"Country-Purpose\",\n",
    "COUNT(\"Country-Purpose\") AS frequency\n",
    "FROM satellite_purpose\n",
    "Group BY \"Country-Purpose\"\n",
    "ORDER BY frequency DESC\n",
    "LIMIT 10;\n",
    "''').as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize this data using the `.bar` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdbcontrib.barplot(satellites_bdb, '''\n",
    "SELECT country_of_operator || \"--\" || purpose AS \"Country-Purpose\", \n",
    "COUNT(\"Country-Purpose\") AS frequency\n",
    "FROM satellite_purpose\n",
    "GROUP BY \"Country-Purpose\"\n",
    "ORDER BY frequency DESC\n",
    "LIMIT 20;\n",
    "''');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
