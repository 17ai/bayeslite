* BayesDB on SQLite3

2014-10-22

Goal:  Make the BayesDB implementation simpler and more flexible, and
allow relational SQL queries in addition to probabilistic BQL queries.

** Data representation

- Table data are stored in a SQLite table with obvious schema.
- Table metadata are represented as before, and stored in a JSON blob
  in the SQLite table bayesdb_table.
- Table columns are listed in SQLite table bayesdb_table_column.
- Model data are stored as JSON blobs in SQLite table bayesdb_model.

** BQL queries

BQL phrases with implicit rows and columns are mapped to SQL
functions, implemented in Python and hooked into SQLite, with explicit
rows and columns.  For example, the BQL query

   ESTIMATE COLUMNS FROM table
     WHERE TYPICALITY > 0.6
       AND CORRELATION WITH name > 0.5
     ORDER BY DEPENDENCE PROBABILITY WITH name

might be mapped into SQL as

   SELECT column.name FROM bayesdb_table_column AS column
     WHERE column.table = 'table'
       AND column_typicality('table', column.name) > 0.6
       AND column_correlation('table', column.name, 'name') > 0.5
             > 0.5
     ORDER BY column_dependence_probability('table', column.name, 'name')

where column_typicality, column_correlation, and
column_dependence_probability are SQL functions that fish the BayesDB
metadata out of SQLite (and, in some cases, e.g. CORRELATION, the
values in the columns in question) and call out to the back end
engine.

Queries that involve subqueries to choose column lists, such as

   INFER (ESTIMATE COLUMNS ...) WHERE ...,

will require BayesDB to send two queries to SQLite, one to estimate
the columns (like above) and another query synthesized from the
resulting column lists -- nothing magic or terribly difficult.

** Named models

Naming models is a matter of adding a `name' column to the
bayesdb_model table.

** Structural constraints

Structural constraints don't seem in principle difficult to implement,
either by post-processing the results of engine calls or by pushing
them into the engine -- just a matter of storing them alongside the
model or table.

** Foreign predictors

I'm inclined to say foreign predictors should be provided by the
Python interface to BayesDB, not by putting a construct into BQL that
refers to Python source code.  E.g.,

   bayesdb.create_foreign_predictor("fooblot", fooblot_simulate_output,
       fooblot_assess_log_density)
   bayesdb.execute("UPDATE MODEL mumble TO MODEL frotz"
       " WITH FOREIGN PREDICTOR fooblot APPLIED TO foo, bar, baz")

** INFER and SIMULATE

In the old BayesDB, the BQL INFER command would perform inference on
each cell separately.  This is the easiest thing to do at the moment
for BayesDB-on-SQLite, but if we wanted to batch inference operations,
we may be able to use SQLite virtual tables to do so.  Similarly, the
BQL SIMULATE command may be implementable as SELECT on a temporary
SQLite virtual table.

** JSON vs relational

Instead of JSON we could convert all metadata to a relational schema,
to make it easier to do many queries exclusively in SQL instead of
partly in SQL and partly in Python (or C++).  Not expedient for now,
though.

** Discrete columns

For discrete columns: should the SQLite table store the string
representation, or the integer code?  I'm inclined toward string
representation so unmodified SQL queries still look nice, and so that
it will be easier to ask BayesDB to do modelling on an existing SQL
table.
