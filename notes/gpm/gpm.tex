\documentclass[10pt,letterpaper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{todonotes}
\usepackage{url}


\newtheorem{example}{Example}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{discussion}{Discussion}[section]
\newtheorem{excercise}{Excercise}[section]
\newtheorem{algorithm}{Algorithm}[section]

\DeclareMathOperator{\argmin}{arg\,min}
\DeclareMathOperator{\argmax}{arg\,max}

\newcommand{\set}[1]{\{#1\}}
\newcommand{\G}{\mathcal{G}}
\newcommand{\T}{\mathcal{T}}

\title{Draft Technical Notes on BayesDB}

\begin{document}

\maketitle

\section{Overview: Generative Population Models and the BayesDB Minimal Modeling Language}
\label{sec:overview}

BQL programs are executed against a set of ambient data
\textit{generative population models} (GPMs).  A GPM is assoicated
with a table in the database, which represents individuals observed
from that population.\footnote{Perhaps partially, if some cells in the
  table are null.} These generative population models are provided by
BayesDB based on modeling schemas and inference programs written in
the BayesDB Minimal Modeling Language.

\subsection{Generative Population Models}

Formally, a GPM is a probability distribution on unbounded-size
populations of individuals (which correspond to rows), with some fixed
set of attributes (which correspond to columns). A ``population'' is
an inherently unordered collection, so the distribution is taken to be
exchangeable.

\begin{example} \label{ex:normal_gpm} A Pretty Normal Generative Population
Model

Consider the following GPM on $D$-dimensional members of
a population $\mathbf{X}$: The individuals $\mathbf{X_i}$ are taken to
be independently identically distributed according to a mixture of two
normal distributions

\[ p_\mathbf{X_i}(x) = w_1\mathcal{N}(x;\mu_1,\Sigma_1) +
 w_2\mathcal{N}(x;\mu_2,\Sigma_2) \]

with fixed parameterization $(w_1, \mu_1, \Sigma_1, w_2, \mu_2, \Sigma_2)$.
\end{example}

While the GPM of Example~\ref{ex:normal_gpm} is valid, in that it is a
probability distribution on arbitrary-size populations, it is not
particularly interesting, because the individuals are independent and
the parameterization is fixed.\footnote{One plausible scenario in
  which such a ``fixed'' GPM can arise is by learning the model
  externally from BayesDB.  A user may decide to import such a GPM
  into BayesDB, without providing a hook for BayesDB to adapt it.}

\todo[inline]{
BayesDB admits the notion of a \emph{conditional GPM} that treats some
attributes as unmodeled inputs, and specifies a probability
distribution on other attributes (see Section~\ref{sec:generators} for
details).  The Minimal Modeling Language (Section~\ref{sec:mml}) permits specifying complete GPMs as
directed, acycling compositions of
such objects (on the columns).}

In typical applications we are interested in \textit{learning the GPM
  from data}. For example, this might be learning the specific
parameters $\theta$ given a fixed generative process $M_i$, or
learning the generative process $M_i$ from some fixed model class
$\mathcal{M}$, or even learning the model class itself $\mathcal{M}$
from a set of competing model classes $\set{\mathcal{M}_k}$.  BayesDB
enables this with its notion of \emph{adaptive generative population
  models}, discussed in Section~\ref{sec:formalism-adaptive-gpm} and
specified in Section~\ref{sec:adaptive_gpm}.

\begin{example}
\todo[inline]{Some trivial approximate adaptive thing?  Maybe a
  two-cluster Gaussian with unknown means and covariances, with the
  collapsed version as ideal-adaptive and the uncollapsed version with
  some inference scheme as approximately adaptive?  Perhaps also MLE
  of the parameters as an alternative to Bayes?}
\end{example}

\subsection{The Minimal Modeling Language}
\label{sec:mml}

The BayesDB Minimal Modeling Language (MML) provides a framework for
associating various GPMs with data tables stored in BayesDB, and
adapting them to the data (learning), if applicable.

The MML includes a \textit{default adaptive generative population
  model} which defines a distribution over a collection of
\textit{GPMs from a default class} using a hierarchal, semi-parametric
Bayesian model derived from CrossCat.

\begin{example} \label{ex:crosscat} CrossCat

A cross-categorization of a data table $\mathbf{X}$ with $D$ columns and $N$ 
rows is
a partition of the columns $(X_1,\dots,X_D)$ into blocks called \textit{views}.
In each view, we have a partition of the rows $(X_1^{i},\dots,X_D^{i})_{i=1}^N$
into blocks called \textit{categories}.

\begin{figure}[ht]
    \centering
\includegraphics[width=0.8\textwidth]{cc.jpeg}
\caption{Some possible cross-categorizations of a table with 3 columns
  and 4 rows.  Any two cells with different colors are taken to be
  independent conditioned on the latent structure.}
\label{fig:cc}
\end{figure}
The collection of all possible column/row partitions $j$ of
$\mathbf{X}$, with their associated component parameters $\theta$,
defines a GPM class:

$\mathcal{M}_\textbf{X} = \set{CC_j^{\theta} \text{ : cross-cat of } \mathbf{X}
\text{ with partition } j \text{ and component model params } \theta}$.

A member of the CrossCat GPM class is a particular
cross- categorization with partition $j$ and component parameters
$CC_j^{\theta^*}$.  Adding a prior over these possible structures
defines an adaptive generative population model.
\end{example}

Unlike Example~\ref{ex:normal_gpm}, the latent information of the GPM
in Example~\ref{ex:crosscat} is structurally dependent on
the statistical population it has produced $\mathbf{X}$. Observing more
generated members $\mathbf{X} \to
\mathbf{X}'$ means the GPM class under consideration grows from
$\mathcal{M}_\textbf{X}$ to $\mathcal{M}_\textbf{X'}$, as both the number of
possible cross-categorizations $j$ and the dimensionality of the vector of
latents $\theta$ increase.

\todo[inline]{The reason I am being so pedantic about this construction is to
explicate various design choices when simulating, sampling, and running
posterior inference. In particular we are going to have to break down the latent
structure into 'global' vs 'row-related' latents to differentiate between
observed and hypothetical members.}

The default adaptive GPM is not obliged to model all columns jointly by
positing some GPM from the CrossCat class. The MML includes modeling
instructions for describing dependence constraints, and specifying a
compositional, directed-acyclic network of arbitrary GPMs implemented by a user.
It also includes inference instructions for initializing adaptive GPMs and
performing updates of the posterior distribution on GPMs.

The MML is thus a complete (but sub-Turing) probabilistic programming language
that interoperates with queries written in BQL. The set of primitive GPMs can be
extended by loading foreign GPMs written in VentureScript or Python, and can be used to
transparently integrate models from disparate probabilistic programming
languages such as Stan and statistical computing environments such as R. Because
BQL programs only depend on the statistical data types of the columns, the
underlying modeling technologies, GPM assumptions, and inference tactics can be
changed without invalidating end-user data analysis workflows.

\section{Interface for Generative Population Models} \label{sec:generators}
A \textit{generative population model} is a probabilistic model of a data
generating process and a statistical population that it has produced. It is
informative to think of this statistical population as an infinite table
$\mathbf{X}$ with a finite number of columns $D$ (representing attributes) and
an infinite number of rows (representing members of the population). A finite
number of rows $r_i \in
\set{1,\dots,N}$ are actually observed, so $\mathbf{X}$ is stored in BayesDB as
an $N \times D$ table. Hypothetical members may be referenced by any other row index,
for example by drawing a random real row index
$r^*\sim U[0,1]$.

\begin{discussion} \label{disc:iid} Technical Aside On IID Rows

The classical statistical framework generally assumes that all members of a
population are independent and identically distributed. While a particular
generator is free to make any assumptions about its population, the IID
assumption is a strong one. The default generator (and almost any generator
being learned under the Bayesian framework) will usually assume that the rows
are not IID but exchangeably coupled. De Finetti's theorem guarantees that there
exists a mixture of random measures $\set{\G_\alpha}$ (which in most
cases is indexed by the latent state of the GPM) where the population is
conditionally IID.

$$p(\mathbf{X}) = \int_\alpha{(\Pi_{i=1}^Np(\mathbf{X}_i|\G_\alpha))d
\mathcal{Q}(\G_\alpha)}$$

The De Finetti measure $\mathcal{Q}$ is the object which defines a distribution
over the (fixed) measures (GPMs) that produce a statistical population. In this
sense, $\mathcal{Q}$ represents the adaptive GPM.

\end{discussion}

Generative population models provide the primitive statistical inferences that
are used by BayesDB to implement inferential queries in BQL. To support all of
BQL, a GPM must provide the ability to \textbf{sample from} and \textbf{evaluate
the log density of}\footnote{With respect to counting measure for variables of
discrete statistical types and Lebesgue measure for continuous.}
all possible marginal distributions subject to equality
constraints for arbitrary subsets of variables.

\subsection{Non-Adaptive GPMs}
\label{sec:non-adaptive_gpm}

Since non-adaptive GPMs are by assumption IID on the individuals in
the population, they admit a simpler interface than adaptive ones.  As
such we present it first, and defer the generalization to
Section~\ref{sec:adaptive_gpm}.

\begin{enumerate}

\item \texttt{$\G$ = initialize(schema = $\Lambda$)}

    Initialize a GPM with the given schema, and return the resulting GPM
    $\G$.

    Each GPM is initialized with a \textit{schema} $\Lambda=$\path{(typed-
    outputs, typed-inputs, body)}. The \path{typed- outputs} component specifies
    the column indexes and statistical types of each column that the GPM will be
    responsible for generating. The \path {typed-inputs} component specifies the
    indexes and statistical types of columns that the GPM can read
    from.  If this set is non-empty, the GPM is \emph{conditional}.
    The \path{body} is a GPM-specific blob (opaque to BayesDB) that contains any
    desired configuration information.

\item \texttt{$\vec{s}$ =
    simulate($\G$, row = $i$, targets = $\set{c_j}_{j=1}^{|T|}$, givens
    = $\set{(c_k, x_{ik})}_{k=1}^{|G|}$)}

    Generate a sample from the specified conditional distribution on columns:
    $$
    \vec{s} \sim p( \set{ \mathbf{X}_{ij} } |
    \set{ \mathbf{X}_{ik} = x_{ik} }, \G).
    $$

    The returned $\vec{s}$ is a $|T|$ dimensional vector.

\item \texttt{$\log p$ =
    logpdf($\G$, row = $i$, targets = $\set{(c_j, x_{ij})}_{j=1}^{|T|}$,
    givens = $\set{(c_k, x_{ik})}_{k=1}^{|G|}$)}

    Evaluate the log probability density of the specified conditional
    distribution on columns at a target point:

    $$
    \log p = \log p( \set{ \mathbf{X}_{ij} = x_{ij} } |
    \set{ \mathbf{X}_{ik} = x_{ik} }, \G).
    $$

    The density is interpreted as marginalizing out all random
    variables that are not mentioned.

\end{enumerate}

The column indexes $c_j, c_k$ referred to above must refer to columns
present in the table---the MML does not have a notion of hypothetical
columns.  Further, the \texttt{target} indexes must be a subset of the
columns in the \texttt{typed-outputs} of the GPM $\G$, and
the \texttt{given} indexes of each query must be a superset of the
\texttt{typed-inputs} of the GPM $\G$.  Note: A client may
specify some of the \texttt{typed-outputs} as \texttt{given} in any
given query.  Doing so picks out a conditional version of the output
distribution.

The row index $i$ may either refer to an individual in the
table, or a hypothetical individual.  In the former case, the
distribution being sampled or assessed is taken as conditional on
whatever latent information is available about that individual, but
\emph{not on any attributes stored in the table} except as repeated in
the \texttt{givens}.  In the latter case, the distribution is taken to
refer to a fresh individual (i.e., marginalizing out any
per-individual latent structure).

\subsection{Formalism for Adaptive GPMs}
\label{sec:formalism-adaptive-gpm}

As outlined in Section \ref{sec:overview}, some GPMs can be learned
from observations $\set{\mathbf{X}_{ij} = x_{ij}}$ of a statistical population
$\mathbf{X}$.  Since we permit the learning to itself be stochastic,
the general case is a family of conditional probability distributions
(of learning results) for all possible sets of observations.  Formally:

\begin{definition} Adaptive Generative Population Model

An \emph{Adaptive Generative Population Model} over a class of GPMs
$\{\G_\alpha\}$ is a family of conditional probability distributions
$\Pi(\G_\alpha|\{\mathbf{X}_{ij} = x_{ij}\})$, for all possible
observation sets $\{x_{ij}\}$.
\end{definition}

\todo[inline]{Figure out whether we want the Adaptive GPM to be defined as a 
family of  conditional distributions $\Pi\set{\mathcal{G}_\alpha}$ indexed by 
$\alpha$, or just define it as  $\Pi$, which is the distribution over the
$\mathcal{G}_\alpha$.}

\begin{example} Linear Regression

Linear regression (with a fixed noise model $\mathcal{E}$) can be viewed as a
conditional adaptive GPM over the class of non-adaptive GPMs
parameterized by the possible regression coefficients $\vec\beta_j$.
For input columns $\{x_j\}$ and output column $y$,
the update rule corresponding to maximum likelihood estimation would be

\[ \vec\beta_j^*|\{x_{ij}, y_i\} = \argmax_{\vec\beta_j^*} \sum_i 
p_{\mathcal{E}}(y_i - x_{ij}^T \beta_j^*). \]

The {\tt simulate} and {\tt logpdf} methods would refer to the
noise distribution around the predicted value for $y$.

\todo[inline]{Clear up this notation.
    How can $x_{ij}$, which is just a cell, have a vector operation?
    What is $j$ indexing?
    We seem to maximize the probability of the noise by subtracting the
    observation from the conditional mean. The more natural
    way to express the MLE is maximize the observation $y_i$ conditioned
    on the data, ie $p(y_i|x_i\beta)$. Although the noise model $\mathcal{E}$
    is fixed, we still do not know the parameters $\sigma$ of the noise,
    and that is typically learned from data as well.
    We are also overloading $\set{x_j}$ to mean columns, observations, etc.}
\end{example}

\begin{example} Exact Bayesian Adaptive GPMs

For any GPM class $\{\G_\alpha\}$, an \emph{exact Bayesian adaptive
  generative population model} is given by a prior
$\Pi(\G_\alpha)$ over
$\{\G_\alpha\}$, and the adaptation rule

\[ \Pi(\G_\alpha|\set{\mathbf{X}_{ij} = x_{ij}}) \propto \Pi(\G_\alpha)
 p(\set{\mathbf{X}_{ij} = x_{ij}}|\G_\alpha), \]

where $p(\cdot|\G_\alpha)$ is the probability of the observed data under
the particular GPM $\G_\alpha$. \label{ex:exact-bayes}

\todo[inline]{I killed the vector notation which I discourage from
    using, especially when coupling a vector with two subscripts and
    throwing it inside a set.
    I brought back the $\mathbf{X}$ the random 
    table, to keep it at the forefront. The table
    is essential to discussion of GPMs, and is a familiar notation.}
\end{example}

\subsection{Incremental Adaptive GPMs}

The desired adaptation rule of an adaptive GPM (such as the exact
Bayesian rule of Example~\ref{ex:exact-bayes}) may not always be
tractable to compute.  BayesDB permits adaptive GPMs to expose a
time-accuracy tradeoff in the form of incremental adaptation, where
the client is invited to select the amount of computational resources
they are willing to commit, and rewarded for greater commitment with a
superior quality of adaptation.  Formally this involves adding a ``fuel''
parameter to the adaptation rule:

\begin{definition} Incremental Adaptive Generative Population Model

An \emph{Incremental Adaptive Generative Population Model} over a class of GPMs
$\{\G_\alpha\}$ is a family of conditional probability distributions
$\Pi_n(\G_\alpha|\set{\mathbf{X}_{ij} = x_{ij}})$, for all possible
observation sets $\{x_{ij}\}$ and all positive integers $n$, where increasing
$n$ represents increasing computational cost.
\end{definition}

\begin{example} Bayesian Markov Adaptive GPMs

For any GPM class $\{\G_\alpha\}$, a \emph{Bayesian Markov adaptive
  generative population model} is given by a prior
$\Pi(\G_\alpha)$ over
$\{\G_\alpha\}$, a data-dependent transition operator
$\T_{\{\vec{x}_{ij}\}}$ over $\{\G_\alpha\}$, and
an adaptation rule that consists of iterating $\T$:

\[ \Pi_n(\G_\alpha|\set{\mathbf{X}_{ij} = x_{ij}}) = \T_{\set{x_{ij}}}^n 
\Pi(\G_\alpha). \]
\label{ex:markov-bayes}
\end{example}

This will be \emph{asymptotically Bayesian} if the transition operator
converges to the true posterior, that is if

\[ \lim_{n\to\infty}D_{KL}(\Pi^*(\G_\alpha) \| \Pi_n(\G_\alpha|\{\vec{x}_{ij}\})) = 0, \]

where $\Pi^*(\G_\alpha|\set{\mathbf{X}_{ij}=x_{ij}}) \propto 
\Pi(\G_\alpha) p(\set{\mathbf{X}_{ij}=x_{ij}}|\G_\alpha)$
as in the exact Bayes case (Example~\ref{ex:exact-bayes}).
If the true data distribution falls into the hypothesis class given by
the prior $\Pi$, this will also be \emph{asymptotically consistent} in
the usual sense.

Since non-incremental adaptive GPMs are a special case of incremental
ones, we will make the assumption of incrementality in the rest of
this document, and omit the adjective.

\subsection{Interface for Adaptive GPMs}
\label{sec:adaptive_gpm}

The extended interface for adaptive GPMs based on Markov chains is outlined
below.  The key differences from the interface to non-adaptive GPMs
defined in Section~\ref{sec:non-adaptive_gpm} are as follows:

\begin{itemize}
\item We add \texttt{incorporate} and \texttt{remove} methods to
  manipulate the set of observed individuals on which the adaptive GPM
  is taken to be conditioned.
\item We add an \texttt{infer} method to control expenditure of
  computation on incremental adaptation.
\item We generalize the \texttt{simulate} and \texttt{logpdf} methods
  to permit querying and conditioning on multiple rows, since the
  joint distribution on several rows need no longer be the product of
  the corresponding marginal distributions.
\end{itemize}

Note: BayesDB implements an algorithm for recovering joint multi-row
simulation in terms of single-row simulations, so the multi-row
version of \texttt{simulate} may be viewed as an optional
optimization.

\todo[inline]{An adaptive GPM can be used as a non-adaptive GPM by
  marginalizing out the distribution over the class it is supposed to
  adapt over.  Technical difficulty: that calls for non-incorporating
  simulations, whereas the promised algorithm for multi-row simulate
  in terms of single-row simulate relies on simulations incorporating
  their results (which is expected to be cheap).}

\todo[inline]{Analogous issue with drawing multiple samples from block
  simulation.  The samples are supposed to be IID; which one does the
  simulation incorporate?}

\begin{enumerate}

\item \texttt{$\G$ = initialize(schema = $\Lambda$)}

    Initializes an adaptive GPM with the given schema \texttt{$\Lambda$ =
    (typed-outputs, typed-inputs, body)}.  This is identical with the
    \texttt{initialize} operation for non-adaptive GPMs.  The distribution $\Pi$
    on adaptations is taken to be conditioned on the empty set of observations
    $\Pi(\G_\alpha|\{\})$.
    
    \todo[inline]{I take it the last sentence is just a fancy way to say ``the 
    prior"?}

\item \texttt{$\vec{s}$ =
    simulate($\G$, targets = $\set{(r_j,c_j)}_{j=1}^{|T|}$, givens
    = $\set{(r_k, c_k, x_{r_kc_k})}_{k=1}^{|G|}$)}

    Generate a joint sample from the specified conditional
    distribution on cells.
    $$
    \vec{s} \sim p( \set{ \mathbf{X}_{r_jc_j} } |
    \set{ \mathbf{X}_{r_kc_k} = x_{r_kc_k} }, \G)
    $$

    Note that $\vec{s}$ is a $|T|$ dimensional vector of the simulated
    values for those cells.  As in the non-adaptive case
    (Section~\ref{sec:non-adaptive_gpm}), row indexes control conditioning
    or lack thereof on per-individual latent structure, but all conditioning
    on manifest structure is determined by the \texttt{givens}.
    
    \todo[inline]{This is as far as we have reached with the rewrite.}

\item \texttt{$\log p$ =
    logpdf($\G$, targets = $\set{(r_i^t, c_i^t, x_{(r_i^t,
    c_i^t)})}_{i=1}^{|T|}$, givens = $\set{(r_i^g, c_i^g, x_{(r_i^g,
    c_i^g)})}_{i=1}^{|G|}$}

    Evaluate the log probability density of the specified conditional
    distribution at a target point.

    $$
    \log p = p( \set{ \mathbf{X}_{(r_i^t,c_i^t)} = x_{(r_i^t,c_i^t)} } |
    \set{ \mathbf{X}_{(r_i^g,c_i^g)} = x_{(r_i^g,c_i^g)} }, \G)
    $$

\item \texttt{incorporate($\G$, value = $(r_j,c_j,x_{(r_j,c_j)})$)}

    Records an observation $x_{(r_j,c_j)}$ in the cell $\mathbf{X_{r_j,c_j}}$.
    If there is no row $r_j$, a new one will be created.

    Errors result from overwriting existing cells, or inserting values
    $x_{(r_j,c_j)}$ incompatible with the meta-schema $\Lambda$ (for example
    providing a wrong data type).

\item \texttt{remove($\G$, $(r_j,c_j$)}

    Removes the observation $x_{(r_i,c_j)}$ stored in cell $\mathbf{X}_{ij}$.

\item \texttt{infer($\G$, program = $\mathcal{P}$)}

    Simulate an internal Markov chain transition operator $\mathcal{T}$ based on
    the inference procedure specified in the program $\mathcal{P}$.

    This inference program is typically designed in cohesion with the
    \texttt{body} specified in the schema $\Lambda$. Each run of \texttt{infer}
    improves the quality of the posterior sample.
\end{enumerate}

Some Markov chain GPMs are \textit{asymptotically Bayesian}:

\begin{equation*}
\lim_{t\to\infty}D_{KL}(p(\theta_\G|\mathbf{X_\G}) ||
p(\mathcal{T}^t(\theta_\G))) = 0
\end{equation*}

A sufficiently expressive asymptotically Bayesian Markov chain GPM may also be
\textit{asymptotically consistent} in the usual sense.

\section{An Ensemble of Adaptive Generative Population Models}
\label{sec:ensemble}

If BayesDB inferences were based on a single instance of a adaptive GPM, the
inferences would arbitrarily suppress modeling uncertainty. The MML provides an
alternative constructor for adaptive GPMs that internally manages and ensemble
of GPMs. In the language of Markov Chains, the ensemble represents a set of
independent, parallel chains.

\begin{enumerate}
\item \texttt{$\mathcal{Q}$ = initialize(schema = $\Lambda$, count = S)}

    Initializes a collection of $N$ GPMs with the schema $\Lambda$.
    $$
    \mathcal{Q} =
    (\set{\G_s = (\theta_{\G}^{(s,0)})}_{s=1}^S,
    \mathbf{X_\mathcal{Q}})
    $$

    Note that the schema and data store are shared across all GPMs in the
    ensemble.
\end{enumerate}

The default ensemble GPM maintains a uniform distribution over all $N$ GPMs and
approximately marginalizes over the posterior on GPMs via the appropriate form
of simple Monte Carlo.

\begin{enumerate}
\item \texttt{simulate} delegates to a randomly sampled Markov chain GPM
$\G_k$ for each of the $N$ samples in the returned set.

    $$
    \set{\vec{s}_i} = \cup_k \texttt{simulate}
    (\G_k,\dots,\texttt{size} = 1) \text{ where }
    \G_k \sim U[\set{\G_s}]
    $$

\item \texttt{logpdf} forms a Monte Carlo estimate of the expected density using
all of the GPMs in the ensemble.

    $$
    \log p = \frac{1}{S}\sum_s\texttt{logpdf}(\G_s)
    $$
\end{enumerate}

Other functions in the GPM interface are defined analogously. More elaborate
methods such as likelihood weighting of posterior samples from each chain are a
possible extension.

\begin{excercise} \label{ex:normal_vs_normal} Testing the Default Generative
Population Model

    Consider a adaptive GPM $\G_N$ which defines a distribution over
    the space of mixture of Gaussian GPMs of the form seen in Example
    \ref{ex:normal_gpm}. Rather than fix the parameters as we did earlier, now
    place a prior over the number of Gaussian components $i$ and the weights,
    means, and covariances $\theta$. Also consider the default GPM
    $\G_{CC}$ from Example \ref{ex:crosscat}, which has a vague prior
    over the cross-categorizations and mixture parameters.

    Suppose a population $\mathbf{X}$ is observed, and we are interested in
    comparing the two GPMs. If you know about the internals of CrossCat, it
    should be clear that the collection of GPMs that $\G_N$ can
    generate is a subset of the GPMs generated by $\G_{CC}$ (how?).

    How can you invoke the GPM interface to test the performance of the default
    metamodel? (Hint: first define a set of ``performance'' metrics and a
    synthetic dataset). Does it make sense for $\G_N$ to outperform
    $\G_{CC}$ in certain regimes? Can you think of other GPMs that are
    special members of the default GPM class (hint: Naive Bayes, \dots), and
    associated tests?
\end{excercise}

\section{Characterizing Probabilistic Dependence}

Many analysis subproblems correspond directly to invocations of the GPM
interface. For example, missing or unknown values can be inferring an set of
results via \texttt{simulate} and reducing these to a point estimate. MAP
prediction can be approximated the single result with the highest likelihood
under \texttt{logpdf}.

The GPM interface is also sufficient to implement generic mechanisms for
characterizing context-specific conditional dependence and independence. This
mechanism can be used to implement additional measures that are useful for data
analysis, such as a context-sensitive measure of similarity.

Below are a collection of queries that can be answered using semantics from the
GPM interface. Consider a GPM $\G$ ascribing to either the primitive or
adaptive GPM interface.

\begin{enumerate}

\item $\set{I_k} = \texttt{CMI}(
    \G,
    A = \set{(r_i^a,c_i^a)}_{i=1}^{|A|}, B = \set{(r_i^b,c_i^b)}_{i=1}^{|B|}, C
    = \set{(r_i^c,c_i^c)}_{i=1}^{|D|}, D =
    \set{(r_i^a,c_i^a,x_{(r_i^a,c_i^a)})}_{i=1}^{|D|},
    \texttt{ accuracy} = N,
    \texttt{ size} = K)$

    CMI is an abbreviation of \texttt{conditional-mutual-information}
    $(A:B|C,D=d)$ under the given GPM. Let $A$, $B$, $C$, and $D$ be subsets of
    the random variables in the infinite random table $\mathbf{X}$ induced by
    the GPM. An important special case in which \texttt{CMI} can be used to
    compute bivariate, unconditional mutual information for distinct variables
    will have $C,D = \emptyset$, $A = \set{(c_1^a,r^*)}$ and $B =
    \set{(c_1^b,r^*)}$, with $r^* \sim U[0,1]$ and $c_1^a \ne c_1^b$.

    One implementation of \texttt{CMI}, applicable to all generators, is Monte
    Carlo estimation as follows.

    \begin{algorithm} \label{alg:cmi}
    First generate a collection of $N$ samples from $(A,B,C)|D=d$, each
    corresponding to a unique member of the population.

    \begin{align*}
    r_i &\sim U[0,1] \text{ where } j \in \set{0,\dots,N-1}\\
    \set{(\hat{a}_j, \hat{b}_j, \hat{c}_j)} &\sim (A,B,C)|D=d\\
    \end{align*}
    These samples can be used to form a Monte Carlo estimate of the desired
    conditional mutual information.

    \begin{align*}
    I(A:B|C,D=d) &:=
        \int \log \frac{p_{C|D=d}(c) p_{A,B,C|D=d}(a,b,c)}
            {p_{A,C|D=d}(a,c) p_{B,C|D=d}(b,c)}dF_{A,B,C|D=d}(a,b,c)\\ & \approx
        \sum_{(a,b,c)\in\set{(\hat{a}_j,\hat{b}_j,\hat{c}_j)}}
         \frac{p_{C|D=d}(\hat{c}_j)
         p_{A,B,C|D=d}(\hat{a}_j,\hat{b}_j,\hat{c}_j)}
         {p_{A,C|D=d}(\hat{a}_j,\hat{c}_j) p_{B,C|D=d}(\hat{b}_j,\hat{c}_j)}
    \end{align*}

    \end{algorithm}

    The output of \texttt{CMI} is set of $K$ estimates $\set{I_k}$, where each
    estimate is created using $N$ samples. This allows us to characterize
    uncertainty over the true value by computing Monte Carlo standard errors and
    other quantities of interest. For a primitive GPM, a single estimate $I_1$ is
    returned, where $N\times K$ samples are used to form the estimate.

    \todo[inline]{I think it is valuable to return a set of estimates even
        for a primitive GPM to characterize uncertainty. By the CLT, the variance
        of the estimator drops as $1/\sqrt{N}$, so using a sample with $NK$
        gives a reduction of variance $\propto 1/\sqrt{K}$ but does not allow us
        to characterize the uncertainty.}

    Note that the samples are generated by invoking
    \begin{align*}
    {\tt simulate(} \G,
    {\tt targets} = \set{(r^*,c_i^a)} \cup \set{r^*,c_i^b} \cup \set{r^*,c_i^c},\\
    {\tt givens} = \set{(r_i^b,c_i^b,x_{(r_i^b,c_i^b)})},
    {\tt size} = 1)
    \end{align*}

    The log densities are evaluated by invoking
    \begin{align*}
    {\tt logpdf(} \G, {\tt targets} = \set{(r^*,c_i^a,\hat{a}_{j,i})}
    \cup\set{r^*,c_i^b,\hat{b}_{j,i}}\cup\set{r^*,c_i^c,,\hat{b}_{j,i}},\\
    {\tt  givens} = \set{(r_i^b,c_i^b,x_{(r_i^b,c_i^b)})}, {\tt size} = 1)
    \end{align*}

    \begin{excercise}
    Consider an alternative implementation of Algorithm \ref{alg:cmi}, where a
    single row index is drawn $r^* \sim U[0,1]$ and $N$ samples are used in
    \texttt{simulate}. Is this an equivalent implementation?
    \end{excercise}

\item $p = \texttt{marginal-dependence-prob}(\G,
    \texttt{colA}=c_i,
    \texttt{colB}=c_j,
    \texttt{accuracy}=N)$

    \todo[inline]{Figure out how to allow the user to set a throttle for desired
        accuracy. Here I am using a generic accuracy term both in marginal-
        depprob and CMI}

    Computes the probability, under the random latent structure of the GPM,
    that the two variables $\mathbf{X}_{r^*,c_i}$ and $\mathbf{X}_{r^*,c_j}$ are
    unconditionally independent.

    \begin{align*}
    \mathbb{P}_\G\set{I(\mathbf{X}_{r^*,c_i} : \mathbf{X}_{r^*,c_j} = 0)}
    \end{align*}

    Given that mutual information is zero if and only the two variables are
    statistically independent, the following simple Monte Carlo procedure is a
    suggested implementation.

    \begin{algorithm} \label{alg:marginal_depprob} First obtain a set of mutual
        information estimates by invoking {\tt CMI}

        \begin{align*}
        \set{I_k} = {\tt CMI}(
        \G,
        A = \set{(r_i^*,c_i)}, B = \set{(r_i^*,c_j)}, C = \emptyset, D =
        \emptyset,\\ {\tt accuracy} = N, {\tt size} = N)
        \end{align*}

        Return the fraction of samples from $\set{I_k}$ for which the mutual
        information is zero
        \begin{align*}
            p = \frac{1}{|\set{I_k}|}\sum_{k}{\mathbb{I}_{\set{0}}(I_k)}
        \end{align*}
    \end{algorithm}

\item $r^2 = \texttt{marginal-dependence-magnitude}(\G,
    \texttt{colA}=c_i,
    \texttt{colB}=c_j,
    \texttt{accuracy}=N)$

    Computes an informational measure of correlation between
    $\mathbf{X}_{r^*,c_i}$ and $\mathbf{X}_{r^*,c_j}$ based on EH Linfoot. The
    implementation is straightforward.

    \begin{algorithm} \label{alg:linfoot} Compute a point estimate for the
        mutual information $I_0$ between $\mathbf{X}_{r^*,c_i}$ and
        $\mathbf{X}_{r^*,c_j}$ using an appropriate invocation of {\tt CMI}.

        Return the Linfoot measure $r^2$

        \begin{align*}
        r^2 = \sqrt{1 - \exp{(-2I_0)}}
        \end{align*}

    \end{algorithm}

    \todo[inline]{Should this function return a point estimate or a collection
    of estimates?}
    \todo[inline]{The Linfoot measure\\
        http://www.sciencedirect.com/science/article/pii/S001999585790116X\\ is
        what has been traditionally used by Bax. Linfoot is normalized between
        [0,1] but there are some questionable properties, if $Y=g(X)$ Linfoot is
        not guaranteed to be 1 (easy to construct example in discrete case).
        Moreover feedback from PPAML is that the zmatrices it produces are
        sparse and uninsightful, and give the implication that continuous
        variables are more dependent than categorical ones.}

\item $r^2 = \texttt{generative-similarity}(\G,
    \texttt{context-vars} = \set{c_i},
    \texttt{rowA}=r_i,
    \texttt{rowB}=r_j,
    \texttt{accuracy}=N)$

    Computes the context-sensitive generative similarity for two members of the
    statistical population. This is defined as the probability, under the random
    latent structure of the GPM, that
    \texttt{rowA} and \texttt{rowB} are identically distributed conditioned on
    \texttt{context-vars}.
    \end{enumerate}

\section{TODOs}

    \todo[inline]{Explain what it means to have 'observed members' of a
    statistical population. In particular, a GPM's latentness can be broken down
    into 'global' and 'row-specific'. Specifying a row index is and implicit
    conditioning any distribution on the row-latents. This idea is mostly
    applicable to GPMs which implicitly cluster the observed population, (and
    carry a distribution over cluster assignments).}

\end{document}
