\documentclass[10pt,letterpaper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{todonotes}
\usepackage{url}


\newtheorem{example}{Example}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{discussion}{Discussion}[section]
\newtheorem{excercise}{Excercise}[section]
\newtheorem{algorithm}{Algorithm}[section]

\DeclareMathOperator{\argmin}{arg\,min}
\DeclareMathOperator{\argmax}{arg\,max}

\newcommand{\set}[1]{\{#1\}}
\newcommand{\G}{\mathcal{G}}
\newcommand{\T}{\mathcal{T}}

\title{Draft Technical Notes on BayesDB}

\begin{document}

\maketitle

\section{Overview: Generative Population Models and the BayesDB Minimal Modeling Language}
\label{sec:overview}

BQL programs are executed against a set of ambient data
\textit{generative population models} (GPMs).  A GPM is assoicated
with a table in the database, which represents individuals observed
from that population.\footnote{Perhaps partially, if some cells in the
  table are null.} These generative population models are provided by
BayesDB based on modeling schemas and inference programs written in
the BayesDB Minimal Modeling Language.

\subsection{Generative Population Models}

Formally, a GPM is a probability distribution on unbounded-size
populations of individuals (which correspond to rows), with some fixed
set of attributes (which correspond to columns). A ``population'' is
an inherently unordered collection, so the distribution is taken to be
exchangeable.

\begin{example} \label{ex:normal_gpm} A Pretty Normal Generative Population
Model

Consider the following GPM on $D$-dimensional members of
a population $\mathbf{X}$: The individuals $\mathbf{X_i}$ are taken to
be independently identically distributed according to a mixture of two
normal distributions

\[ p_\mathbf{X_i}(x) = w_1\mathcal{N}(x;\mu_1,\Sigma_1) + w_2\mathcal{N}(x;\mu_2,\Sigma_2) \]

with fixed parameterization $(w_1, \mu_1, \Sigma_1, w_2, \mu_2, \Sigma_2)$.
\end{example}

While the GPM of Example~\ref{ex:normal_gpm} is valid, in that it is a
probability distribution on arbitrary-size populations, it is not
particularly interesting, because the individuals are independent and
the parameterization is fixed.\footnote{One plausible scenario in
  which such a ``fixed'' GPM can arise is by learning the model
  externally from BayesDB.  A user may decide to import such a GPM
  into BayesDB, without providing a hook for BayesDB to adapt it.}

\todo[inline]{
BayesDB admits the notion of a \emph{conditional GPM} that treats some
attributes as unmodeled inputs, and specifies a probability
distribution on other attributes (see Section~\ref{sec:generators} for
details).  The Minimal Modeling Language (Section~\ref{sec:mml}) permits specifying complete GPMs as
directed, acycling compositions of
such objects (on the columns).}

In typical applications we are interested in \textit{learning
the GPM from data}. For example, this might be learning the specific
parameters $\theta$ given a fixed generative process $M_i$, or learning the
generative process $M_i$ from some fixed model class $\mathcal{M}$, or even
learning the model class itself $\mathcal{M}$ from a set of competing model
classes $\set{\mathcal{M}_k}$.

Learning from data is feasible if we assume some commonality between
the individuals of a population.  This amounts to supposing that the
distribution on populations is not IID on individuals.  Since it
is nonetheless exchangeable, de Finetti's theorem \todo{cite}
permits us to treat it as a distribution over (unobserved) distributions
over individuals.

We are thus led to the following formal structure:

\begin{eqnarray*}
\hat{\theta} & \sim & \Pi(.) \\
\theta_i & \sim & \pi(.|\hat\theta) \qquad \textrm{for each individual $i$} \\
\vec{x}_{ij} & \sim & q(.|\theta_i, \hat\theta)
\end{eqnarray*}

Here $\hat\theta$ is some arbitrary latent structure shared among the
population, presumed distributed according to distribution $\Pi$ (a
priori of observing any data); $\theta_i$ is per-individual latent
structure, assumed independent across individuals conditioned on
$\hat\theta$; and $\vec{x}_{ij}$ are the observable per-individual
features that correspond to cells in the data table.  A GPM of this form is given by the
sample spaces for $\hat\theta$, $\theta_i$, and $\vec{x}_{ij}$, and by the
distributions $\Pi(.)$, $\pi(.|\hat\theta)$, and $q(.|\theta_i, \hat\theta)$.

\begin{remark}
For any fixed value of $\hat\theta$, the marginal composition

\begin{eqnarray}
 p(\vec{x}_{ij}|\hat\theta) & = &
 \int_{\theta_i} q(\vec{x}_{ij}|\theta_i, \hat\theta) \pi(\theta_i|\hat\theta)
 \label{eqn:marginal-individual}
\end{eqnarray}

itself gives a valid generative population model (whose individuals
are independent). \label{rem:gpm-class}
\end{remark}
This is an example of a \emph{GPM class}, in this
case parameterized on $\hat\theta$.

The above theory justifies the possibility of learning.  Given a
particular initial GPM $\G$, observations of some individuals
$\{\vec{x}_{ij}\}_{i \in I}$ license a change in the distribution
$\Pi(\hat\theta)$ to a data-dependent distribution
$\Pi(\hat\theta|\{\vec{x}_{ij}\})$ on $\hat\theta$ that applies to
further individuals from the population.  An \emph{adaptive generative
  population model} (Section~\ref{sec:adaptive_gpm}) is a GPM equipped
with a computational capability to adapt to data in that framework.

We might imagine an \emph{exactly Bayesian adaptive generative population model}
as one whose posterior distribution $\Pi(.|\{\vec{x}_{ij}\})$ on
$\hat\theta$ is given by Bayes' Rule:

\[ \Pi(\hat\theta|\{\vec{x}_{ij}\}) \propto \Pi(\hat\theta) p(\{\vec{x}_{ij}\}|\hat\theta), \]

where the $\Pi(.)$ on the right hand side is the prior and the $p(.|\hat\theta)$
marginalizes out the per-individual latent variables $\theta_i$ (eqn~\ref{eqn:marginal-individual}).
Since this is not computationally tractable in general, but admits
anytime approximations of increasing quality (e.g., by running a Markov chain
transition operators for more steps), the
interface defined in Section~\ref{sec:adaptive_gpm} also admits
iteratively adaptive GPMs that expose a throttle on computational
effort.

\begin{example}
\todo[inline]{Some trivial approximate adaptive thing?  Maybe a
  two-cluster Gaussian with unknown means and covariances, with the
  collapsed version as ideal-adaptive and the uncollapsed version with
  some inference scheme as approximately adaptive?  Perhaps also MLE
  of the parameters as an alternative to Bayes?}
\end{example}

\subsection{The Minimal Modeling Language}
\label{sec:mml}

The BayesDB Minimal Modeling Language (MML) provides a framework for
associating various GPMs with data tables stored in BayesDB, and
adapting them to the data (learning), if applicable.

The MML includes a \textit{default adaptive generative population
  model} which defines a distribution over a collection of
\textit{GPMs from a default class} using a hierarchal, semi-parametric
Bayesian model derived from CrossCat.

\begin{example} \label{ex:crosscat} CrossCat

A cross-categorization of a data table $\mathbf{X}$ with $D$ columns and $N$ rows is
a partition of the columns $(X_1,\dots,X_D)$ into blocks called \textit{views}.
In each view, we have a partition of the rows $(X_1^{i},\dots,X_D^{i})_{i=1}^N$
into blocks called \textit{categories}.

\begin{figure}[ht]
    \centering
\includegraphics[width=0.8\textwidth]{cc.jpeg}
\caption{Some possible cross-categorizations of a table with 3 columns
  and 4 rows.  Any two cells with different colors are taken to be
  independent conditioned on the latent structure.}
\label{fig:cc}
\end{figure}
The collection of all possible column/row partitions $j$ of
$\mathbf{X}$, with their associated component parameters $\theta$,
defines a GPM class:

$\mathcal{M}_\textbf{X} = \set{CC_j^{\theta} \text{ : cross-cat of } \mathbf{X}
\text{ with partition } j \text{ and component model params } \theta}$.

A member of the CrossCat GPM class is a particular
cross- categorization with partition $j$ and component parameters
$CC_j^{\theta^*}$.  Adding a prior over these possible structures
defines an adaptive generative population model.
\end{example}

Unlike Example~\ref{ex:normal_gpm}, the latent information of the GPM
in Example~\ref{ex:crosscat} is structurally dependent on
the statistical population it has produced $\mathbf{X}$. Observing more
generated members $\mathbf{X} \to
\mathbf{X}'$ means the GPM class under consideration grows from
$\mathcal{M}_\textbf{X}$ to $\mathcal{M}_\textbf{X'}$, as both the number of
possible cross-categorizations $j$ and the dimensionality of the vector of
latents $\theta$ increase.

\todo[inline]{The reason I am being so pedantic about this construction is to
explicate various design choices when simulating, sampling, and running
posterior inference. In particular we are going to have to break down the latent
structure into 'global' vs 'row-related' latents to differentiate between
observed and hypothetical members.}

The default adaptive GPM is not obliged to model all columns jointly by
positing some GPM from the CrossCat class. The MML includes modeling
instructions for describing dependence constraints, and specifying a
compositional, directed-acyclic network of arbitrary GPMs implemented by a user.
It also includes inference instructions for initializing adaptive GPMs and
performing updates of the posterior distribution on GPMs.

The MML is thus a complete (but sub-Turing) probabilistic programming language
that interoperates with queries written in BQL. The set of primitive GPMs can be
extended by loading foreign GPMs written in VentureScript or Python, and can be used to
transparently integrate models from disparate probabilistic programming
languages such as Stan and statistical computing environments such as R. Because
BQL programs only depend on the statistical data types of the columns, the
underlying modeling technologies, GPM assumptions, and inference tactics can be
changed without invalidating end-user data analysis workflows.

\section{Interface for Generative Population Models} \label{sec:generators}
A \textit{generative population model} is a probabilistic model of a data
generating process and a statistical population that it has produced. It is
informative to think of this statistical population as an infinite table
$\mathbf{X}$ with a finite number of columns $D$ (representing attributes) and
an infinite number of rows (representing members of the population). A finite
number of rows $r_i \in
\set{1,\dots,N}$ are actually observed, so $\mathbf{X}$ is stored in BayesDB as
an $N \times D$ table. Hypothetical members may be referenced by any other row index,
for example by drawing a random real row index
$r^*\sim U[0,1]$.

\begin{discussion} \label{disc:iid} Technical Aside On IID Rows

The classical statistical framework generally assumes that all members of a
population are independent and identically distributed. While a particular
generator is free to make any assumptions about its population, the IID
assumption is a strong one. The default generator (and almost any generator
being learned under the Bayesian framework) will usually assume that the rows
are not IID but exchangeably coupled. De Finetti's theorem guarantees that there
exists a mixture of random measures $\set{\G_\alpha}$ (which in most
cases is indexed by the latent state of the GPM) where the population is
conditionally IID.

$$p(\mathbf{X}) = \int_\alpha{(\Pi_{i=1}^Np(\mathbf{X}_i|\G_\alpha))d
\mathcal{Q}(\G_\alpha)}$$

The De Finetti measure $\mathcal{Q}$ is the object which defines a distribution
over the (fixed) measures (GPMs) that produce a statistical population. In this
sense, $\mathcal{Q}$ represents the adaptive GPM.

\end{discussion}

Generative population models provide the primitive statistical inferences that
are used by BayesDB to implement inferential queries in BQL. To support all of
BQL, a GPM must provide the ability to \textbf{sample from} and \textbf{evaluate
the log density of}\footnote{With respect to counting measure for variables of
discrete statistical types and Lebesgue measure for continuous}
all possible marginal distributions subject to equality
constraints for arbitrary subsets of variables.

\subsection{Non-Adaptive GPMs}

Since non-adaptive GPMs are by assumption IID on the individuals in
the population, they admit a simpler interface than adaptive ones.  As
such we present it first, and defer the generalization to
Section~\ref{sec:adaptive_gpm}.

\begin{enumerate}

\item \texttt{$\G$ = initialize(schema = $\Lambda$)}

    Initialize a GPM with the given schema, and return the resulting GPM
    $\G$.

    Each GPM is initialized with a \textit{schema} $\Lambda=$\path{(typed-
    outputs, typed-inputs, body)}. The \path{typed- outputs} component specifies
    the column indexes and statistical types of each column that the GPM will be
    responsible for generating. The \path {typed-inputs} component specifies the
    indexes and statistical types of columns that the GPM can read
    from.  If this set is non-empty, the GPM is \emph{conditional}.
    The \path{body} is a GPM-specific blob (opaque to BayesDB) that contains any
    desired configuration information.

\item \texttt{$\vec{s}_i$ =
    simulate($\G$, row = $i$, targets = $\set{c_j}_{j=1}^{|T|}$, givens
    = $\set{(c_k, x_{ik})}_{k=1}^{|G|}$)}

    Generate a sample from the specified conditional distribution on columns:
    $$
    \vec{s} \sim p( \set{ \mathbf{X}_{ij} } |
    \set{ \mathbf{X}_{ik} = x_{ik} }, \G).
    $$

    The returned $\vec{s}$ is a $|T|$ dimensional vector.

\item \texttt{$\log p$ =
    logpdf($\G$, row = $i$, targets = $\set{(c_j, x_{ij})}_{j=1}^{|T|}$,
    givens = $\set{(c_k, x_{ik})}_{k=1}^{|G|}$)}

    Evaluate the log probability density of the specified conditional
    distribution on columns at a target point:

    $$
    \log p = p( \set{ \mathbf{X}_{ij} = x_{ij} } |
    \set{ \mathbf{X}_{ik} = x_{ik} }, \G).
    $$

    The density is interpreted as marginalizing out all random
    variables that are not mentioned.

\end{enumerate}

The column indexes $c_j, c_k$ referred to above must refer to columns
present in the table---the MML does not have a notion of hypothetical
columns.  Further, the \texttt{target} indexes must be a subset of the
columns in the \texttt{typed-outputs} of the GPM $\G$, and
the \texttt{given} indexes of each query must be a superset of the
\texttt{typed-inputs} of the GPM $\G$.  Note: A client may
specify some of the \texttt{typed-outputs} as \texttt{given} in any
given query.  Doing so picks out a conditional version of the output
distribution.

The row index $i$ may either refer to an individual in the
table, or a hypothetical individual.  In the former case, the
distribution being sampled or assessed is taken as conditional on
whatever latent information is available about that individual, but
\emph{not on any attributes stored in the table} except as repeated in
the \texttt{givens}.  In the latter case, the distribution is taken to
refer to a fresh individual (i.e., marginalizing out any
per-individual latent structure).

\subsection{Formalism for Adaptive GPMs}

As outlined in Section \ref{sec:overview}, some GPMs can be learned
from observations $\{x_{ij}\}$ of a statistical population
$\mathbf{X}$.  Since we permit the learning to itself be stochastic,
the general case is a family of conditional probability distributions
(of learning results) for all possible sets of observations.  Formally:

\begin{definition} Adaptive Generative Population Model

An \emph{Adaptive Generative Population Model} over a class of GPMs
$\{\G_\alpha\}$ is a family of conditional probability distributions
$\Pi(\G_\alpha|\{\mathbf{X}_{ij} = x_{ij}\})$, for all possible
observation sets $\{x_{ij}\}$.
\end{definition}

\begin{example} Linear Regression

Linear regression (with a fixed noise model $\mathcal{N}$) can be viewed as a
conditional adaptive GPM over the class of non-adaptive GPMs
parameterized by the possible regression coefficients $\vec\beta_j$.
For input columns $\{x_j\}$ and output column $y$,
the update rule corresponding to maximum likelihood estimation would be

\[ \vec\beta_j^*|\{x_{ij}, y_i\} = \argmax_{\vec\beta_j^*} \sum_i p_{\mathcal{N}}(y_i - x_{ij}^T \beta_j^*). \]

The \texttt{simulate} and \texttt{logpdf} methods would refer to the
noise distribution around the predicted value for $y$.
\end{example}

\begin{example} Exact Bayesian Adaptive GPMs

For any GPM class $\{\G_\alpha\}$, an \emph{exact Bayesian adaptive
  generative population model} is given by a prior
$\Pi(\G_\alpha)$ over
$\{\G_\alpha\}$, and the adaptation rule

\[ \Pi(\G_\alpha|\{\vec{x}_{ij}\}) \propto \Pi(\G_\alpha) p(\{\vec{x}_{ij}\}|\G_\alpha), \]

where $p(.|\G_\alpha)$ is the probability of the observed data under
the particular GPM $\G_\alpha$. \label{ex:exact-bayes}
\end{example}

\subsection{Incremental Adaptive GPMs}

The desired adaptation rule of an adaptive GPM (such as the exact
Bayesian rule of Example~\ref{ex:exact-bayes}) may not always be
tractable to compute.  BayesDB permits adaptive GPMs to expose a
time-accuracy tradeoff in the form of incremental adaptation, where
the client is invited to select the amount of computational resources
they are willing to commit, and rewarded for greater commitment with a
superior quality of adaptation.  Formally this involves adding a ``fuel''
parameter to the adaptation rule:

\begin{definition} Incremental Adaptive Generative Population Model

An \emph{Incremental Adaptive Generative Population Model} over a class of GPMs
$\{\G_\alpha\}$ is a family of conditional probability distributions
$\Pi_n(\G_\alpha|\{\mathbf{X}_{ij} = x_{ij}\})$, for all possible
observation sets $\{x_{ij}\}$ and all positive integers $n$, where increasing
$n$ represents increasing computational cost.
\end{definition}

\begin{example} Bayesian Markov Adaptive GPMs

For any GPM class $\{\G_\alpha\}$, a \emph{Bayesian Markov adaptive
  generative population model} is given by a prior
$\Pi(\G_\alpha)$ over
$\{\G_\alpha\}$, a data-dependent transition operator
$\T_{\{\vec{x}_{ij}\}}$ over $\{\G_\alpha\}$, and
an adaptation rule that consists of iterating $\T$:

\[ \Pi_n(\G_\alpha|\{\vec{x}_{ij}\}) = \T_{\{\vec{x}_{ij}\}}^n \Pi(\G_\alpha). \]
\label{ex:markov-bayes}
\end{example}

This will be \emph{asymptotically Bayesian} if the transition operator
converges to the true posterior, that is if

\[ \lim_{n\to\infty}D_{KL}(\Pi^*(\G_\alpha) \| \Pi_n(\G_\alpha|\{\vec{x}_{ij}\})) = 0, \]

where $\Pi^*(\G_\alpha|\{\vec{x}_{ij}\}) \propto \Pi(\G_\alpha) p(\{\vec{x}_{ij}\}|\G_\alpha)$
as in the exact Bayes case (Example~\ref{ex:exact-bayes}).
If the true data distribution falls into the hypothesis class given by
the prior $\Pi$, this will also be \emph{asymptotically consistent} in
the usual sense.

Since non-incremental adaptive GPMs are a special case of incremental
ones, we will make the assumption of incrementality in the rest of
this document, and omit the adjective.

\subsection{Interface for Adaptive GPMs}
\label{sec:adaptive_gpm}

Learning the GPM structure will be
based on approximate probabilistic inference in a \textit{adaptive generative
population model} $\G$ which is a probabilistic model defined over a
space of GPMs $\set{\mathcal{G_\alpha}}$. The GPMs $\G_\alpha$
typically share structure (such as belonging to the same parametric class) but
this is not a formal restriction.

A key insight about a adaptive GPM $\G$ is that it can \textit{answer
the same questions about the underlying statistical population} $\mathbf{X}$
that any one of its GPMs $\G_\alpha$ can. These questions are answered
achieved by an appropriate sequence of sampling, conditioning, and
marginalization operations over the space of GPMs $\G_\alpha$.
Moreover, a adaptive GPM $\mathcal{Q}$ can itself define a distribution over a
space of adaptive GPMs, up to an infinitely deep level of recursion.

Thus far, all adaptive GPMs in BayesDB have been based on \textit{Markov chain}
methods. These adaptive GPMs internally maintain a sample from an approximate
posterior over GPMS, and provide a Markov chain transition operator that updates
the sample stochastically. Some Markov chains are \textit{asymptotically
Bayesian} in the sense that the distribution that results from sequences of $T$
updates converges to the posterior over GPMs as $T$ tends to infinity.

The extended interface for adaptive GPMs based on Markov chains is outlined
below:

\begin{enumerate}

\item \texttt{$\G$ = initialize(schema = $\Lambda$)}

    Initializes a adaptive GPM with the given schema \texttt{$\Lambda$ =
    (typed-outputs, typed-inputs, body)}, and returns an arbitrary
    initialization $\theta_\G^0$ and empty tabular data store
    $\mathbf{X}_\G$.

    \todo[inline]{If there are columns in \texttt{typed-outputs} or \texttt
    {typed-inputs} for which no generative procedure is defined in
    \texttt{body}, then the default GPM will be used to jointly model those
    columns. This is required because the MML needs a full generative model to
    query arbitrary patterns of population members. Otherwise several important
    queries would be ill-defined (for instance, simulating an output without
    conditioning on an input).}

\item \texttt{$\set{\vec{s}_i}_{i=1}^N$ =
    simulate($\G$, targets = $\set{(r_i^t,c_i^t)}_{i=1}^{|T|}$, givens
    = $\set{(r_i^g, c_i^g, x_{(r_i^g, c_i^g)})}_{i=1}^{|G|}$, samples = $N$)}

    Generate $N$ samples from the specified conditional distribution.
    $$
    \set{\vec{s}_i}_{i=1}^N \sim p( \set{ \mathbf{X}_{(r_i^t,c_i^t)} } |
    \set{ \mathbf{X}_{(r_i^g,c_i^g)} = x_{(r_i^g,c_i^g)} }, \G)
    $$

    Note that each $\vec{s}_i$ is a $|T|$ dimensional vector.

\item \texttt{$\log p$ =
    logpdf($\G$, targets = $\set{(r_i^t, c_i^t, x_{(r_i^t,
    c_i^t)})}_{i=1}^{|T|}$, givens = $\set{(r_i^g, c_i^g, x_{(r_i^g,
    c_i^g)})}_{i=1}^{|G|}$}

    Evaluate the log probability density of the specified conditional
    distribution at a target point.

    $$
    \log p = p( \set{ \mathbf{X}_{(r_i^t,c_i^t)} = x_{(r_i^t,c_i^t)} } |
    \set{ \mathbf{X}_{(r_i^g,c_i^g)} = x_{(r_i^g,c_i^g)} }, \G)
    $$

\item \texttt{incorporate(value = $(r_j,c_j,x_{(r_j,c_j)})$)}

    Records an observation $x_{(r_j,c_j)}$ in the cell $\mathbf{X_{r_j,c_j}}$.
    If there is no row $r_j$, a new one will be created.

    Errors result from overwriting existing cells, or inserting values
    $x_{(r_j,c_j)}$ incompatible with the meta-schema $\Lambda$ (for example
    providing a wrong data type).

\item \texttt{remove($(r_j,c_j$)}

    Removes the observation $x_{(r_i,c_j)}$ stored in cell $\mathbf{X}_{ij}$.

\item \texttt{infer(program = $\mathcal{P}$)}

    Simulate an internal Markov chain transition operator $\mathcal{T}$ based on
    the inference procedure specified in the program $\mathcal{P}$.

    This inference program is typically designed in cohesion with the
    \texttt{body} specified in the schema $\Lambda$. Each run of \texttt{infer}
    improves the quality of the posterior sample.
\end{enumerate}

Some Markov chain GPMs are \textit{asymptotically Bayesian}:

\begin{equation*}
\lim_{t\to\infty}D_{KL}(p(\theta_\G|\mathbf{X_\G}) ||
p(\mathcal{T}^t(\theta_\G))) = 0
\end{equation*}

A sufficiently expressive asymptotically Bayesian Markov chain GPM may also be
\textit{asymptotically consistent} in the usual sense.

\section{An Ensemble of Adaptive Generative Population Models}
\label{sec:ensemble}

If BayesDB inferences were based on a single instance of a adaptive GPM, the
inferences would arbitrarily suppress modeling uncertainty. The MML provides an
alternative constructor for adaptive GPMs that internally manages and ensemble
of GPMs. In the language of Markov Chains, the ensemble represents a set of
independent, parallel chains.

\begin{enumerate}
\item \texttt{$\mathcal{Q}$ = initialize(schema = $\Lambda$, count = S)}

    Initializes a collection of $N$ GPMs with the schema $\Lambda$.
    $$
    \mathcal{Q} =
    (\set{\G_s = (\theta_{\G}^{(s,0)})}_{s=1}^S,
    \mathbf{X_\mathcal{Q}})
    $$

    Note that the schema and data store are shared across all GPMs in the
    ensemble.
\end{enumerate}

The default ensemble GPM maintains a uniform distribution over all $N$ GPMs and
approximately marginalizes over the posterior on GPMs via the appropriate form
of simple Monte Carlo.

\begin{enumerate}
\item \texttt{simulate} delegates to a randomly sampled Markov chain GPM
$\G_k$ for each of the $N$ samples in the returned set.

    $$
    \set{\vec{s}_i} = \cup_k \texttt{simulate}
    (\G_k,\dots,\texttt{size} = 1) \text{ where }
    \G_k \sim U[\set{\G_s}]
    $$

\item \texttt{logpdf} forms a Monte Carlo estimate of the expected density using
all of the GPMs in the ensemble.

    $$
    \log p = \frac{1}{S}\sum_s\texttt{logpdf}(\G_s)
    $$
\end{enumerate}

Other functions in the GPM interface are defined analogously. More elaborate
methods such as likelihood weighting of posterior samples from each chain are a
possible extension.

\begin{excercise} \label{ex:normal_vs_normal} Testing the Default Generative
Population Model

    Consider a adaptive GPM $\G_N$ which defines a distribution over
    the space of mixture of Gaussian GPMs of the form seen in Example
    \ref{ex:normal_gpm}. Rather than fix the parameters as we did earlier, now
    place a prior over the number of Gaussian components $i$ and the weights,
    means, and covariances $\theta$. Also consider the default GPM
    $\G_{CC}$ from Example \ref{ex:crosscat}, which has a vague prior
    over the cross-categorizations and mixture parameters.

    Suppose a population $\mathbf{X}$ is observed, and we are interested in
    comparing the two GPMs. If you know about the internals of CrossCat, it
    should be clear that the collection of GPMs that $\G_N$ can
    generate is a subset of the GPMs generated by $\G_{CC}$ (how?).

    How can you invoke the GPM interface to test the performance of the default
    metamodel? (Hint: first define a set of ``performance'' metrics and a
    synthetic dataset). Does it make sense for $\G_N$ to outperform
    $\G_{CC}$ in certain regimes? Can you think of other GPMs that are
    special members of the default GPM class (hint: Naive Bayes, \dots), and
    associated tests?
\end{excercise}

\section{Characterizing Probabilistic Dependence}

Many analysis subproblems correspond directly to invocations of the GPM
interface. For example, missing or unknown values can be inferring an set of
results via \texttt{simulate} and reducing these to a point estimate. MAP
prediction can be approximated the single result with the highest likelihood
under \texttt{logpdf}.

The GPM interface is also sufficient to implement generic mechanisms for
characterizing context-specific conditional dependence and independence. This
mechanism can be used to implement additional measures that are useful for data
analysis, such as a context-sensitive measure of similarity.

Below are a collection of queries that can be answered using semantics from the
GPM interface. Consider a GPM $\G$ ascribing to either the primitive or
adaptive GPM interface.

\begin{enumerate}

\item $\set{I_k} = \texttt{CMI}(
    \G,
    A = \set{(r_i^a,c_i^a)}_{i=1}^{|A|}, B = \set{(r_i^b,c_i^b)}_{i=1}^{|B|}, C
    = \set{(r_i^c,c_i^c)}_{i=1}^{|D|}, D =
    \set{(r_i^a,c_i^a,x_{(r_i^a,c_i^a)})}_{i=1}^{|D|},
    \texttt{ accuracy} = N,
    \texttt{ size} = K)$

    CMI is an abbreviation of \texttt{conditional-mutual-information}
    $(A:B|C,D=d)$ under the given GPM. Let $A$, $B$, $C$, and $D$ be subsets of
    the random variables in the infinite random table $\mathbf{X}$ induced by
    the GPM. An important special case in which \texttt{CMI} can be used to
    compute bivariate, unconditional mutual information for distinct variables
    will have $C,D = \emptyset$, $A = \set{(c_1^a,r^*)}$ and $B =
    \set{(c_1^b,r^*)}$, with $r^* \sim U[0,1]$ and $c_1^a \ne c_1^b$.

    One implementation of \texttt{CMI}, applicable to all generators, is Monte
    Carlo estimation as follows.

    \begin{algorithm} \label{alg:cmi}
    First generate a collection of $N$ samples from $(A,B,C)|D=d$, each
    corresponding to a unique member of the population.

    \begin{align*}
    r_i &\sim U[0,1] \text{ where } j \in \set{0,\dots,N-1}\\
    \set{(\hat{a}_j, \hat{b}_j, \hat{c}_j)} &\sim (A,B,C)|D=d\\
    \end{align*}
    These samples can be used to form a Monte Carlo estimate of the desired
    conditional mutual information.

    \begin{align*}
    I(A:B|C,D=d) &:=
        \int \log \frac{p_{C|D=d}(c) p_{A,B,C|D=d}(a,b,c)}
            {p_{A,C|D=d}(a,c) p_{B,C|D=d}(b,c)}dF_{A,B,C|D=d}(a,b,c)\\ & \approx
        \sum_{(a,b,c)\in\set{(\hat{a}_j,\hat{b}_j,\hat{c}_j)}}
         \frac{p_{C|D=d}(\hat{c}_j)
         p_{A,B,C|D=d}(\hat{a}_j,\hat{b}_j,\hat{c}_j)}
         {p_{A,C|D=d}(\hat{a}_j,\hat{c}_j) p_{B,C|D=d}(\hat{b}_j,\hat{c}_j)}
    \end{align*}

    \end{algorithm}

    The output of \texttt{CMI} is set of $K$ estimates $\set{I_k}$, where each
    estimate is created using $N$ samples. This allows us to characterize
    uncertainty over the true value by computing Monte Carlo standard errors and
    other quantities of interest. For a primitive GPM, a single estimate $I_1$ is
    returned, where $N\times K$ samples are used to form the estimate.

    \todo[inline]{I think it is valuable to return a set of estimates even
        for a primitive GPM to characterize uncertainty. By the CLT, the variance
        of the estimator drops as $1/\sqrt{N}$, so using a sample with $NK$
        gives a reduction of variance $\propto 1/\sqrt{K}$ but does not allow us
        to characterize the uncertainty.}

    Note that the samples are generated by invoking
    \begin{align*}
    {\tt simulate(} \G,
    {\tt targets} = \set{(r^*,c_i^a)} \cup \set{r^*,c_i^b} \cup \set{r^*,c_i^c},\\
    {\tt givens} = \set{(r_i^b,c_i^b,x_{(r_i^b,c_i^b)})},
    {\tt size} = 1)
    \end{align*}

    The log densities are evaluated by invoking
    \begin{align*}
    {\tt logpdf(} \G, {\tt targets} = \set{(r^*,c_i^a,\hat{a}_{j,i})}
    \cup\set{r^*,c_i^b,\hat{b}_{j,i}}\cup\set{r^*,c_i^c,,\hat{b}_{j,i}},\\
    {\tt  givens} = \set{(r_i^b,c_i^b,x_{(r_i^b,c_i^b)})}, {\tt size} = 1)
    \end{align*}

    \begin{excercise}
    Consider an alternative implementation of Algorithm \ref{alg:cmi}, where a
    single row index is drawn $r^* \sim U[0,1]$ and $N$ samples are used in
    \texttt{simulate}. Is this an equivalent implementation?
    \end{excercise}

\item $p = \texttt{marginal-dependence-prob}(\G,
    \texttt{colA}=c_i,
    \texttt{colB}=c_j,
    \texttt{accuracy}=N)$

    \todo[inline]{Figure out how to allow the user to set a throttle for desired
        accuracy. Here I am using a generic accuracy term both in marginal-
        depprob and CMI}

    Computes the probability, under the random latent structure of the GPM,
    that the two variables $\mathbf{X}_{r^*,c_i}$ and $\mathbf{X}_{r^*,c_j}$ are
    unconditionally independent.

    \begin{align*}
    \mathbb{P}_\G\set{I(\mathbf{X}_{r^*,c_i} : \mathbf{X}_{r^*,c_j} = 0)}
    \end{align*}

    Given that mutual information is zero if and only the two variables are
    statistically independent, the following simple Monte Carlo procedure is a
    suggested implementation.

    \begin{algorithm} \label{alg:marginal_depprob} First obtain a set of mutual
        information estimates by invoking {\tt CMI}

        \begin{align*}
        \set{I_k} = {\tt CMI}(
        \G,
        A = \set{(r_i^*,c_i)}, B = \set{(r_i^*,c_j)}, C = \emptyset, D =
        \emptyset,\\ {\tt accuracy} = N, {\tt size} = N)
        \end{align*}

        Return the fraction of samples from $\set{I_k}$ for which the mutual
        information is zero
        \begin{align*}
            p = \frac{1}{|\set{I_k}|}\sum_{k}{\mathbb{I}_{\set{0}}(I_k)}
        \end{align*}
    \end{algorithm}

\item $r^2 = \texttt{marginal-dependence-magnitude}(\G,
    \texttt{colA}=c_i,
    \texttt{colB}=c_j,
    \texttt{accuracy}=N)$

    Computes an informational measure of correlation between
    $\mathbf{X}_{r^*,c_i}$ and $\mathbf{X}_{r^*,c_j}$ based on EH Linfoot. The
    implementation is straightforward.

    \begin{algorithm} \label{alg:linfoot} Compute a point estimate for the
        mutual information $I_0$ between $\mathbf{X}_{r^*,c_i}$ and
        $\mathbf{X}_{r^*,c_j}$ using an appropriate invocation of {\tt CMI}.

        Return the Linfoot measure $r^2$

        \begin{align*}
        r^2 = \sqrt{1 - \exp{(-2I_0)}}
        \end{align*}

    \end{algorithm}

    \todo[inline]{Should this function return a point estimate or a collection
    of estimates?}
    \todo[inline]{The Linfoot measure\\
        http://www.sciencedirect.com/science/article/pii/S001999585790116X\\ is
        what has been traditionally used by Bax. Linfoot is normalized between
        [0,1] but there are some questionable properties, if $Y=g(X)$ Linfoot is
        not guaranteed to be 1 (easy to construct example in discrete case).
        Moreover feedback from PPAML is that the zmatrices it produces are
        sparse and uninsightful, and give the implication that continuous
        variables are more dependent than categorical ones.}

\item $r^2 = \texttt{generative-similarity}(\G,
    \texttt{context-vars} = \set{c_i},
    \texttt{rowA}=r_i,
    \texttt{rowB}=r_j,
    \texttt{accuracy}=N)$

    Computes the context-sensitive generative similarity for two members of the
    statistical population. This is defined as the probability, under the random
    latent structure of the GPM, that
    \texttt{rowA} and \texttt{rowB} are identically distributed conditioned on
    \texttt{context-vars}.
    \end{enumerate}

\section{TODOs}

    \todo[inline]{Explain what it means to have 'observed members' of a
    statistical population. In particular, a GPM's latentness can be broken down
    into 'global' and 'row-specific'. Specifying a row index is and implicit
    conditioning any distribution on the row-latents. This idea is mostly
    applicable to GPMs which implicitly cluster the observed population, (and
    carry a distribution over cluster assignments).}

\end{document}
